<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>LangChain Graph 详解：构建智能知识图谱 | Chico Gong's Tech Blog</title><meta name=keywords content="LangChain,知识图谱,Graph,大语言模型,LLM"><meta name=description content='引言
在人工智能和大语言模型(LLM)的应用中，知识的表示与组织方式直接影响系统的推理能力和智能水平。LangChain Graph 作为LangChain生态系统中的重要组件，提供了一套强大的工具，使开发者能够轻松地从文本中提取结构化知识，构建知识图谱，并基于图进行复杂推理。本文将深入探讨LangChain Graph的概念、工作原理、应用场景以及实践技巧，帮助您全面理解和应用这一强大工具。
知识图谱与LangChain Graph基础
什么是知识图谱？
知识图谱(Knowledge Graph)是一种结构化数据模型，用于表示实体(Entities)之间的关系(Relations)。它以图的形式组织信息，其中：

节点(Nodes)：代表实体或概念
边(Edges)：代表实体间的关系

graph LR
    A["艾伦·图灵"] -->|"发明"| B["图灵机"]
    A -->|"出生于"| C["英国"]
    A -->|"被誉为"| D["计算机科学之父"]
    B -->|"是"| E["理论计算模型"]
LangChain Graph的定义与价值
LangChain Graph是LangChain框架中专注于知识图谱构建、存储和查询的模块集合。它将LLM的自然语言处理能力与图数据库的结构化表示结合，实现了：

自动从文本中提取实体和关系
构建和维护知识图谱
基于图结构进行复杂查询和推理
增强LLM应用的上下文理解和回答质量

LangChain Graph架构
LangChain Graph的整体架构可以通过以下图示来理解：
flowchart TB
    subgraph "输入层"
        A["文本文档"] --> B["网页内容"]
        C["结构化数据"] --> D["用户查询"]
    end
    
    subgraph "处理层"
        E["实体提取<br>EntityExtractor"]
        F["关系提取<br>RelationExtractor"]
        G["知识图谱构建<br>KnowledgeGraphCreator"]
    end
    
    subgraph "存储层"
        H["图数据库<br>Neo4j/NetworkX"]
        I["向量存储<br>VectorStores"]
    end
    
    subgraph "应用层"
        J["图查询<br>GraphQuery"]
        K["图推理<br>GraphReasoning"]
        L["QA系统<br>GraphQAChain"]
    end
    
    A --> E
    B --> E
    C --> F
    D --> F
    E --> G
    F --> G
    G --> H
    G --> I
    H --> J
    H --> K
    I --> L
核心组件详解
1. 实体和关系提取器
这些组件负责从文本中识别实体和它们之间的关系：'><meta name=author content="Chico Gong"><link rel=canonical href=https://realtime-ai.chat/2024/12/27/langchain-graph-%E8%AF%A6%E8%A7%A3%E6%9E%84%E5%BB%BA%E6%99%BA%E8%83%BD%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/><link crossorigin=anonymous href=/assets/css/stylesheet.2211ca3164be7830024f6aad2b3a2e520843a64f8f048445c3401c1249aa051d.css integrity="sha256-IhHKMWS+eDACT2qtKzouUghDpk+PBIRFw0AcEkmqBR0=" rel="preload stylesheet" as=style><link rel=icon href=https://realtime-ai.chat/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://realtime-ai.chat/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://realtime-ai.chat/favicon-32x32.png><link rel=apple-touch-icon href=https://realtime-ai.chat/apple-touch-icon.png><link rel=mask-icon href=https://realtime-ai.chat/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://realtime-ai.chat/2024/12/27/langchain-graph-%E8%AF%A6%E8%A7%A3%E6%9E%84%E5%BB%BA%E6%99%BA%E8%83%BD%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://realtime-ai.chat/2024/12/27/langchain-graph-%E8%AF%A6%E8%A7%A3%E6%9E%84%E5%BB%BA%E6%99%BA%E8%83%BD%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"><meta property="og:site_name" content="Chico Gong's Tech Blog"><meta property="og:title" content="LangChain Graph 详解：构建智能知识图谱"><meta property="og:description" content='引言 在人工智能和大语言模型(LLM)的应用中，知识的表示与组织方式直接影响系统的推理能力和智能水平。LangChain Graph 作为LangChain生态系统中的重要组件，提供了一套强大的工具，使开发者能够轻松地从文本中提取结构化知识，构建知识图谱，并基于图进行复杂推理。本文将深入探讨LangChain Graph的概念、工作原理、应用场景以及实践技巧，帮助您全面理解和应用这一强大工具。
知识图谱与LangChain Graph基础 什么是知识图谱？ 知识图谱(Knowledge Graph)是一种结构化数据模型，用于表示实体(Entities)之间的关系(Relations)。它以图的形式组织信息，其中：
节点(Nodes)：代表实体或概念 边(Edges)：代表实体间的关系 graph LR A["艾伦·图灵"] -->|"发明"| B["图灵机"] A -->|"出生于"| C["英国"] A -->|"被誉为"| D["计算机科学之父"] B -->|"是"| E["理论计算模型"] LangChain Graph的定义与价值 LangChain Graph是LangChain框架中专注于知识图谱构建、存储和查询的模块集合。它将LLM的自然语言处理能力与图数据库的结构化表示结合，实现了：
自动从文本中提取实体和关系 构建和维护知识图谱 基于图结构进行复杂查询和推理 增强LLM应用的上下文理解和回答质量 LangChain Graph架构 LangChain Graph的整体架构可以通过以下图示来理解：
flowchart TB subgraph "输入层" A["文本文档"] --> B["网页内容"] C["结构化数据"] --> D["用户查询"] end subgraph "处理层" E["实体提取<br>EntityExtractor"] F["关系提取<br>RelationExtractor"] G["知识图谱构建<br>KnowledgeGraphCreator"] end subgraph "存储层" H["图数据库<br>Neo4j/NetworkX"] I["向量存储<br>VectorStores"] end subgraph "应用层" J["图查询<br>GraphQuery"] K["图推理<br>GraphReasoning"] L["QA系统<br>GraphQAChain"] end A --> E B --> E C --> F D --> F E --> G F --> G G --> H G --> I H --> J H --> K I --> L 核心组件详解 1. 实体和关系提取器 这些组件负责从文本中识别实体和它们之间的关系：'><meta property="og:locale" content="zh-cn"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-12-27T00:00:00+00:00"><meta property="article:modified_time" content="2024-12-27T00:00:00+00:00"><meta property="article:tag" content="LangChain"><meta property="article:tag" content="知识图谱"><meta property="article:tag" content="Graph"><meta property="article:tag" content="大语言模型"><meta property="article:tag" content="LLM"><meta name=twitter:card content="summary"><meta name=twitter:title content="LangChain Graph 详解：构建智能知识图谱"><meta name=twitter:description content='引言
在人工智能和大语言模型(LLM)的应用中，知识的表示与组织方式直接影响系统的推理能力和智能水平。LangChain Graph 作为LangChain生态系统中的重要组件，提供了一套强大的工具，使开发者能够轻松地从文本中提取结构化知识，构建知识图谱，并基于图进行复杂推理。本文将深入探讨LangChain Graph的概念、工作原理、应用场景以及实践技巧，帮助您全面理解和应用这一强大工具。
知识图谱与LangChain Graph基础
什么是知识图谱？
知识图谱(Knowledge Graph)是一种结构化数据模型，用于表示实体(Entities)之间的关系(Relations)。它以图的形式组织信息，其中：

节点(Nodes)：代表实体或概念
边(Edges)：代表实体间的关系

graph LR
    A["艾伦·图灵"] -->|"发明"| B["图灵机"]
    A -->|"出生于"| C["英国"]
    A -->|"被誉为"| D["计算机科学之父"]
    B -->|"是"| E["理论计算模型"]
LangChain Graph的定义与价值
LangChain Graph是LangChain框架中专注于知识图谱构建、存储和查询的模块集合。它将LLM的自然语言处理能力与图数据库的结构化表示结合，实现了：

自动从文本中提取实体和关系
构建和维护知识图谱
基于图结构进行复杂查询和推理
增强LLM应用的上下文理解和回答质量

LangChain Graph架构
LangChain Graph的整体架构可以通过以下图示来理解：
flowchart TB
    subgraph "输入层"
        A["文本文档"] --> B["网页内容"]
        C["结构化数据"] --> D["用户查询"]
    end
    
    subgraph "处理层"
        E["实体提取<br>EntityExtractor"]
        F["关系提取<br>RelationExtractor"]
        G["知识图谱构建<br>KnowledgeGraphCreator"]
    end
    
    subgraph "存储层"
        H["图数据库<br>Neo4j/NetworkX"]
        I["向量存储<br>VectorStores"]
    end
    
    subgraph "应用层"
        J["图查询<br>GraphQuery"]
        K["图推理<br>GraphReasoning"]
        L["QA系统<br>GraphQAChain"]
    end
    
    A --> E
    B --> E
    C --> F
    D --> F
    E --> G
    F --> G
    G --> H
    G --> I
    H --> J
    H --> K
    I --> L
核心组件详解
1. 实体和关系提取器
这些组件负责从文本中识别实体和它们之间的关系：'><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://realtime-ai.chat/posts/"},{"@type":"ListItem","position":2,"name":"LangChain Graph 详解：构建智能知识图谱","item":"https://realtime-ai.chat/2024/12/27/langchain-graph-%E8%AF%A6%E8%A7%A3%E6%9E%84%E5%BB%BA%E6%99%BA%E8%83%BD%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"LangChain Graph 详解：构建智能知识图谱","name":"LangChain Graph 详解：构建智能知识图谱","description":"引言 在人工智能和大语言模型(LLM)的应用中，知识的表示与组织方式直接影响系统的推理能力和智能水平。LangChain Graph 作为LangChain生态系统中的重要组件，提供了一套强大的工具，使开发者能够轻松地从文本中提取结构化知识，构建知识图谱，并基于图进行复杂推理。本文将深入探讨LangChain Graph的概念、工作原理、应用场景以及实践技巧，帮助您全面理解和应用这一强大工具。\n知识图谱与LangChain Graph基础 什么是知识图谱？ 知识图谱(Knowledge Graph)是一种结构化数据模型，用于表示实体(Entities)之间的关系(Relations)。它以图的形式组织信息，其中：\n节点(Nodes)：代表实体或概念 边(Edges)：代表实体间的关系 graph LR A[\u0026#34;艾伦·图灵\u0026#34;] --\u0026gt;|\u0026#34;发明\u0026#34;| B[\u0026#34;图灵机\u0026#34;] A --\u0026gt;|\u0026#34;出生于\u0026#34;| C[\u0026#34;英国\u0026#34;] A --\u0026gt;|\u0026#34;被誉为\u0026#34;| D[\u0026#34;计算机科学之父\u0026#34;] B --\u0026gt;|\u0026#34;是\u0026#34;| E[\u0026#34;理论计算模型\u0026#34;] LangChain Graph的定义与价值 LangChain Graph是LangChain框架中专注于知识图谱构建、存储和查询的模块集合。它将LLM的自然语言处理能力与图数据库的结构化表示结合，实现了：\n自动从文本中提取实体和关系 构建和维护知识图谱 基于图结构进行复杂查询和推理 增强LLM应用的上下文理解和回答质量 LangChain Graph架构 LangChain Graph的整体架构可以通过以下图示来理解：\nflowchart TB subgraph \u0026#34;输入层\u0026#34; A[\u0026#34;文本文档\u0026#34;] --\u0026gt; B[\u0026#34;网页内容\u0026#34;] C[\u0026#34;结构化数据\u0026#34;] --\u0026gt; D[\u0026#34;用户查询\u0026#34;] end subgraph \u0026#34;处理层\u0026#34; E[\u0026#34;实体提取\u0026lt;br\u0026gt;EntityExtractor\u0026#34;] F[\u0026#34;关系提取\u0026lt;br\u0026gt;RelationExtractor\u0026#34;] G[\u0026#34;知识图谱构建\u0026lt;br\u0026gt;KnowledgeGraphCreator\u0026#34;] end subgraph \u0026#34;存储层\u0026#34; H[\u0026#34;图数据库\u0026lt;br\u0026gt;Neo4j/NetworkX\u0026#34;] I[\u0026#34;向量存储\u0026lt;br\u0026gt;VectorStores\u0026#34;] end subgraph \u0026#34;应用层\u0026#34; J[\u0026#34;图查询\u0026lt;br\u0026gt;GraphQuery\u0026#34;] K[\u0026#34;图推理\u0026lt;br\u0026gt;GraphReasoning\u0026#34;] L[\u0026#34;QA系统\u0026lt;br\u0026gt;GraphQAChain\u0026#34;] end A --\u0026gt; E B --\u0026gt; E C --\u0026gt; F D --\u0026gt; F E --\u0026gt; G F --\u0026gt; G G --\u0026gt; H G --\u0026gt; I H --\u0026gt; J H --\u0026gt; K I --\u0026gt; L 核心组件详解 1. 实体和关系提取器 这些组件负责从文本中识别实体和它们之间的关系：\n","keywords":["LangChain","知识图谱","Graph","大语言模型","LLM"],"articleBody":"引言 在人工智能和大语言模型(LLM)的应用中，知识的表示与组织方式直接影响系统的推理能力和智能水平。LangChain Graph 作为LangChain生态系统中的重要组件，提供了一套强大的工具，使开发者能够轻松地从文本中提取结构化知识，构建知识图谱，并基于图进行复杂推理。本文将深入探讨LangChain Graph的概念、工作原理、应用场景以及实践技巧，帮助您全面理解和应用这一强大工具。\n知识图谱与LangChain Graph基础 什么是知识图谱？ 知识图谱(Knowledge Graph)是一种结构化数据模型，用于表示实体(Entities)之间的关系(Relations)。它以图的形式组织信息，其中：\n节点(Nodes)：代表实体或概念 边(Edges)：代表实体间的关系 graph LR A[\"艾伦·图灵\"] --\u003e|\"发明\"| B[\"图灵机\"] A --\u003e|\"出生于\"| C[\"英国\"] A --\u003e|\"被誉为\"| D[\"计算机科学之父\"] B --\u003e|\"是\"| E[\"理论计算模型\"] LangChain Graph的定义与价值 LangChain Graph是LangChain框架中专注于知识图谱构建、存储和查询的模块集合。它将LLM的自然语言处理能力与图数据库的结构化表示结合，实现了：\n自动从文本中提取实体和关系 构建和维护知识图谱 基于图结构进行复杂查询和推理 增强LLM应用的上下文理解和回答质量 LangChain Graph架构 LangChain Graph的整体架构可以通过以下图示来理解：\nflowchart TB subgraph \"输入层\" A[\"文本文档\"] --\u003e B[\"网页内容\"] C[\"结构化数据\"] --\u003e D[\"用户查询\"] end subgraph \"处理层\" E[\"实体提取\nEntityExtractor\"] F[\"关系提取\nRelationExtractor\"] G[\"知识图谱构建\nKnowledgeGraphCreator\"] end subgraph \"存储层\" H[\"图数据库\nNeo4j/NetworkX\"] I[\"向量存储\nVectorStores\"] end subgraph \"应用层\" J[\"图查询\nGraphQuery\"] K[\"图推理\nGraphReasoning\"] L[\"QA系统\nGraphQAChain\"] end A --\u003e E B --\u003e E C --\u003e F D --\u003e F E --\u003e G F --\u003e G G --\u003e H G --\u003e I H --\u003e J H --\u003e K I --\u003e L 核心组件详解 1. 实体和关系提取器 这些组件负责从文本中识别实体和它们之间的关系：\nsequenceDiagram participant Text as 文本输入 participant LLM as 大语言模型 participant EE as EntityExtractor participant RE as RelationExtractor participant KG as 知识图谱 Text-\u003e\u003eLLM: 发送文本 LLM-\u003e\u003eEE: 提取实体 EE-\u003e\u003eRE: 传递识别的实体 RE-\u003e\u003eLLM: 使用LLM确定实体间关系 RE-\u003e\u003eKG: 构建三元组(主体-关系-客体) 2. 知识图谱构建 flowchart LR A[\"文本\"] --\u003e B{\"实体提取\"} B --\u003e |\"人物/地点/组织等\"| C[\"实体列表\"] C --\u003e D{\"关系提取\"} D --\u003e |\"分析实体间关联\"| E[\"三元组集合\"] E --\u003e F[\"知识图谱构建器\"] F --\u003e G[(\"图数据库\")] F --\u003e H[\"内存图\"] 3. 图存储和查询 LangChain Graph支持多种图存储方式：\ngraph TD A[\"知识图谱数据\"] --\u003e B{\"存储方式\"} B --\u003e|\"内存存储\"| C[\"NetworkX\"] B --\u003e|\"图数据库\"| D[\"Neo4j\"] B --\u003e|\"向量数据库\"| E[\"Chroma/FAISS等\"] C --\u003e F{\"查询方式\"} D --\u003e F E --\u003e F F --\u003e|\"Cypher查询\"| G[\"Neo4j查询\"] F --\u003e|\"图算法\"| H[\"NetworkX算法\"] F --\u003e|\"自然语言\"| I[\"LLM辅助查询\"] 构建知识图谱的工作流程 以下是使用LangChain Graph构建知识图谱的完整流程：\nflowchart TD A[\"准备文本数据\"] --\u003e B[\"文本处理和分块\"] B --\u003e C[\"实体提取\"] C --\u003e D[\"关系识别\"] D --\u003e E[\"三元组生成\"] E --\u003e F[\"图构建和存储\"] F --\u003e G[\"图查询和利用\"] subgraph \"文本处理阶段\" A B end subgraph \"信息提取阶段\" C D E end subgraph \"图构建阶段\" F end subgraph \"应用阶段\" G end 实际代码示例 让我们通过实际代码来理解LangChain Graph的使用方法。\n1. 基础设置 // 导入必要的包 import { ChatOpenAI } from \"@langchain/openai\"; import { EntityExtractor, RelationExtractor, KnowledgeGraph } from \"langchain/graphs\"; import { Neo4jGraph } from \"langchain/graphs/neo4j_graph\"; import { Document } from \"langchain/document\"; // 初始化LLM const llm = new ChatOpenAI({ temperature: 0, model: \"gpt-4-turbo\" }); 2. 从文本构建知识图谱 // 准备文本 const text = ` 艾伦·图灵于1912年出生于英国伦敦。他是计算机科学和人工智能的先驱。 图灵在剑桥大学国王学院和普林斯顿大学学习。他于1936年发表了关于图灵机的论文。 在第二次世界大战期间，图灵在英国密码破译中心布莱切利园工作，成功破解了德国的英格玛密码。 `; // 创建文档 const docs = [ new Document({ pageContent: text }) ]; // 初始化Neo4j图数据库连接 const graph = await Neo4jGraph.initialize({ url: \"neo4j://localhost:7687\", username: \"neo4j\", password: \"password\" }); // 创建知识图谱构建器 const kg = new KnowledgeGraph({ llm, entityExtractor: new EntityExtractor({ llm }), relationExtractor: new RelationExtractor({ llm }) }); // 从文本构建知识图谱 await kg.buildFromDocuments(docs, { graph }); 3. 查询知识图谱 // Cypher查询 const cypherQuery = ` MATCH (p:Person {name: '艾伦·图灵'})-[r]-\u003e(o) RETURN p, r, o `; const result = await graph.query(cypherQuery); console.log(result); // 自然语言查询 import { GraphCypherQAChain } from \"langchain/chains\"; const chain = GraphCypherQAChain.fromLLM({ llm, graph, verbose: true }); const answer = await chain.invoke({ query: \"艾伦·图灵在哪里上的大学？\" }); console.log(answer.text); 应用场景图解 1. 智能问答系统 sequenceDiagram actor User as 用户 participant QA as QA系统 participant LLM as 大语言模型 participant KG as 知识图谱 User-\u003e\u003eQA: 提问 QA-\u003e\u003eLLM: 分析问题 LLM-\u003e\u003eQA: 确定查询意图 QA-\u003e\u003eKG: 构建图查询 KG-\u003e\u003eQA: 返回相关子图 QA-\u003e\u003eLLM: 基于子图生成回答 LLM-\u003e\u003eQA: 生成回答 QA-\u003e\u003eUser: 呈现回答 2. 知识发现与推理 graph TD A[\"文档集合\"] --\u003e B[\"知识图谱\"] B --\u003e C{\"路径分析\"} B --\u003e D{\"社区发现\"} B --\u003e E{\"关系推断\"} C --\u003e F[\"隐藏关联发现\"] D --\u003e G[\"领域聚类\"] E --\u003e H[\"新知识产生\"] F --\u003e I[\"知识增强的应用\"] G --\u003e I H --\u003e I 3. 内容推荐系统 flowchart LR A[\"用户\"] --\u003e B{\"兴趣提取\"} B --\u003e C[\"用户实体图\"] D[\"内容库\"] --\u003e E{\"内容分析\"} E --\u003e F[\"内容知识图\"] C --\u003e G{\"图匹配算法\"} F --\u003e G G --\u003e H[\"个性化推荐\"] H --\u003e A 高级用法：复杂知识图谱 1. 多源数据集成 flowchart TB A1[\"文本文档\"] --\u003e B[\"数据预处理\"] A2[\"结构化数据\"] --\u003e B A3[\"网页内容\"] --\u003e B A4[\"APIs\"] --\u003e B B --\u003e C{\"实体统一\"} C --\u003e D{\"关系提取\"} D --\u003e E[\"图构建\"] E --\u003e F{\"图增强\"} F --\u003e G[\"实体链接\"] F --\u003e H[\"异构合并\"] F --\u003e I[\"冲突消解\"] G --\u003e J[\"完整知识图谱\"] H --\u003e J I --\u003e J 2. 图引导的推理增强 flowchart LR A[\"用户查询\"] --\u003e B{\"分析意图\"} B --\u003e C[\"知识图谱查询\"] C --\u003e D[\"子图检索\"] D --\u003e E{\"构建提示\"} E --\u003e F[\"边界约束\"] E --\u003e G[\"路径引导\"] E --\u003e H[\"属性填充\"] F --\u003e I[\"增强提示\"] G --\u003e I H --\u003e I I --\u003e J[\"LLM推理\"] J --\u003e K[\"精确回答\"] 代码实现：复杂查询示例 // 创建自定义实体和关系提取器 const entityExtractor = new EntityExtractor({ llm, allowedEntityTypes: [\"Person\", \"Organization\", \"Location\", \"Event\", \"Work\", \"Concept\"], contextWindowSize: 3000 }); const relationExtractor = new RelationExtractor({ llm, relationExtractionPrompt: `识别以下文本中实体之间的关系，并以(主体, 关系, 客体)的形式返回。注意关系应该是具体且有意义的动词短语。`, validateRelations: true, maxRelationsPerEntityPair: 3 }); // 实现增量式图构建 async function incrementalGraphBuild(documents, graph) { const kg = new KnowledgeGraph({ llm, entityExtractor, relationExtractor }); // 批处理文档 const batchSize = 5; for (let i = 0; i \u003c documents.length; i += batchSize) { const batch = documents.slice(i, i + batchSize); console.log(`处理批次 ${Math.floor(i/batchSize) + 1}/${Math.ceil(documents.length/batchSize)}`); await kg.buildFromDocuments(batch, { graph, mergeEntities: true // 合并同名实体 }); } return graph; } // 复杂查询示例 async function complexGraphQuery(graph, query) { const chain = GraphCypherQAChain.fromLLM({ llm: new ChatOpenAI({ model: \"gpt-4\", temperature: 0 }), graph, returnDirect: false, // 不直接返回Cypher查询结果 cypherPrompt: `根据以下问题，生成适当的Cypher查询以从知识图谱中检索相关信息。考虑使用图算法和复杂模式匹配。` }); return chain.invoke({ query }); } 最佳实践与优化技巧 1. 实体和关系定义策略 graph TD A[\"定义实体类型\"] --\u003e B{\"选择粒度\"} B --\u003e |\"粗粒度\"| C[\"主要类别\n如人/地点/组织\"] B --\u003e |\"细粒度\"| D[\"详细类别\n如政治家/城市/科技公司\"] C --\u003e E{\"关系定义\"} D --\u003e E E --\u003e |\"语义明确\"| F[\"精确关系\n如'创立'而非'关联'\"] E --\u003e |\"一致性\"| G[\"标准化关系名称\"] F --\u003e H[\"图模式设计\"] G --\u003e H H --\u003e I[\"属性与关系区分\"] H --\u003e J[\"多重关系处理\"] 2. 性能优化技巧 对于大规模知识图谱，以下优化技巧至关重要：\nflowchart TD A[\"性能优化\"] --\u003e B{\"处理大型文档\"} A --\u003e C{\"查询优化\"} A --\u003e D{\"存储策略\"} B --\u003e B1[\"分块处理\"] B --\u003e B2[\"并行提取\"] B --\u003e B3[\"批量处理\"] C --\u003e C1[\"查询缓存\"] C --\u003e C2[\"索引优化\"] C --\u003e C3[\"查询重写\"] D --\u003e D1[\"图数据分区\"] D --\u003e D2[\"冷热数据分离\"] D --\u003e D3[\"增量更新\"] 完整工作流：从文档到智能应用 下面是一个完整的工作流，展示了如何从文档构建知识图谱并应用到实际应用场景：\nflowchart TD subgraph \"数据准备\" A1[\"文档收集\"] --\u003e A2[\"文档清洗\"] A2 --\u003e A3[\"文档分块\"] end subgraph \"知识提取\" A3 --\u003e B1[\"实体识别\"] B1 --\u003e B2[\"关系提取\"] B2 --\u003e B3[\"属性提取\"] end subgraph \"图构建与存储\" B3 --\u003e C1[\"三元组生成\"] C1 --\u003e C2[\"图构建\"] C2 --\u003e C3[\"图存储\"] end subgraph \"图增强\" C3 --\u003e D1[\"实体链接\"] D1 --\u003e D2[\"推理扩展\"] D2 --\u003e D3[\"图验证\"] end subgraph \"应用集成\" D3 --\u003e E1[\"问答系统\"] D3 --\u003e E2[\"搜索增强\"] D3 --\u003e E3[\"内容推荐\"] D3 --\u003e E4[\"决策支持\"] end 实际案例：研究领域知识图谱 以下是一个构建学术研究领域知识图谱的完整示例：\n// 示例：构建AI研究领域知识图谱 import { OpenAI } from \"@langchain/openai\"; import { RecursiveCharacterTextSplitter } from \"langchain/text_splitter\"; import { EntityExtractor, RelationExtractor, KnowledgeGraph } from \"langchain/graphs\"; import { Neo4jGraph } from \"langchain/graphs/neo4j_graph\"; import { GraphRAGRetriever } from \"langchain/retrievers/graph_rag\"; import { RetrievalQAChain } from \"langchain/chains\"; import { Document } from \"langchain/document\"; async function buildResearchGraph(papers, graph) { // 初始化LLM const llm = new ChatOpenAI({ temperature: 0, model: \"gpt-4\" }); // 自定义实体提取器 const entityExtractor = new EntityExtractor({ llm, allowedEntityTypes: [ \"Researcher\", \"Paper\", \"University\", \"Conference\", \"ResearchField\", \"Method\", \"Algorithm\", \"Dataset\" ] }); // 自定义关系提取器 const relationExtractor = new RelationExtractor({ llm, validateRelations: true }); // 初始化知识图谱构建器 const kg = new KnowledgeGraph({ llm, entityExtractor, relationExtractor }); // 文本分割 const textSplitter = new RecursiveCharacterTextSplitter({ chunkSize: 2000, chunkOverlap: 200 }); // 处理每篇论文 for (const paper of papers) { console.log(`处理论文: ${paper.title}`); // 创建文档 const text = `标题: ${paper.title}\\n作者: ${paper.authors.join(', ')}\\n摘要: ${paper.abstract}\\n关键字: ${paper.keywords.join(', ')}`; const docs = await textSplitter.createDocuments([text]); // 构建图 await kg.buildFromDocuments(docs, { graph, mergeEntities: true }); } return graph; } // 基于图的检索增强生成 async function graphBasedAnswering(graph, query) { const llm = new ChatOpenAI({ model: \"gpt-4\" }); // 创建图检索器 const retriever = new GraphRAGRetriever({ graph, llm, searchDepth: 3, // 图搜索深度 maxHops: 2 // 最大跳数 }); // 创建问答链 const chain = RetrievalQAChain.fromLLM(llm, retriever); // 获取答案 const response = await chain.invoke({ query }); return response; } 总结 LangChain Graph为开发者提供了强大的工具集，使从非结构化文本构建知识图谱变得简单而高效。通过结合LLM的语义理解能力与图数据库的结构化表示，它开启了一系列新的应用可能性：\n语义增强的信息检索：超越简单的关键词匹配 复杂关系推理：发现隐藏的知识连接 上下文感知回答：基于图结构的精准回答 知识整合与管理：连接多源异构数据 随着LLM技术和图数据库的不断发展，LangChain Graph将在智能知识系统中扮演越来越重要的角色，为构建下一代AI应用提供强大支持。\n无论您是希望增强现有LLM应用的上下文理解能力，还是构建专门的知识管理系统，LangChain Graph都是一个值得深入学习和掌握的强大工具。\n扩展阅读 LangChain官方文档：Graphs模块 Neo4j与LangChain集成指南 知识图谱构建最佳实践 图神经网络与LLM结合案例 ","wordCount":"1080","inLanguage":"en","datePublished":"2024-12-27T00:00:00Z","dateModified":"2024-12-27T00:00:00Z","author":{"@type":"Person","name":"Chico Gong"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://realtime-ai.chat/2024/12/27/langchain-graph-%E8%AF%A6%E8%A7%A3%E6%9E%84%E5%BB%BA%E6%99%BA%E8%83%BD%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},"publisher":{"@type":"Organization","name":"Chico Gong's Tech Blog","logo":{"@type":"ImageObject","url":"https://realtime-ai.chat/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://realtime-ai.chat/ accesskey=h title="Chico Gong's Tech Blog (Alt + H)">Chico Gong's Tech Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://realtime-ai.chat/ title=首页><span>首页</span></a></li><li><a href=https://realtime-ai.chat/posts/ title=文章><span>文章</span></a></li><li><a href=https://realtime-ai.chat/tags/ title=标签><span>标签</span></a></li><li><a href=https://realtime-ai.chat/about/ title=关于><span>关于</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">LangChain Graph 详解：构建智能知识图谱</h1><div class=post-meta><span title='2024-12-27 00:00:00 +0000 UTC'>2024-12-27</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;Chico Gong</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e5%bc%95%e8%a8%80 aria-label=引言>引言</a></li><li><a href=#%e7%9f%a5%e8%af%86%e5%9b%be%e8%b0%b1%e4%b8%8elangchain-graph%e5%9f%ba%e7%a1%80 aria-label="知识图谱与LangChain Graph基础">知识图谱与LangChain Graph基础</a><ul><li><a href=#%e4%bb%80%e4%b9%88%e6%98%af%e7%9f%a5%e8%af%86%e5%9b%be%e8%b0%b1 aria-label=什么是知识图谱？>什么是知识图谱？</a></li><li><a href=#langchain-graph%e7%9a%84%e5%ae%9a%e4%b9%89%e4%b8%8e%e4%bb%b7%e5%80%bc aria-label="LangChain Graph的定义与价值">LangChain Graph的定义与价值</a></li></ul></li><li><a href=#langchain-graph%e6%9e%b6%e6%9e%84 aria-label="LangChain Graph架构">LangChain Graph架构</a></li><li><a href=#%e6%a0%b8%e5%bf%83%e7%bb%84%e4%bb%b6%e8%af%a6%e8%a7%a3 aria-label=核心组件详解>核心组件详解</a><ul><li><a href=#1-%e5%ae%9e%e4%bd%93%e5%92%8c%e5%85%b3%e7%b3%bb%e6%8f%90%e5%8f%96%e5%99%a8 aria-label="1. 实体和关系提取器">1. 实体和关系提取器</a></li><li><a href=#2-%e7%9f%a5%e8%af%86%e5%9b%be%e8%b0%b1%e6%9e%84%e5%bb%ba aria-label="2. 知识图谱构建">2. 知识图谱构建</a></li><li><a href=#3-%e5%9b%be%e5%ad%98%e5%82%a8%e5%92%8c%e6%9f%a5%e8%af%a2 aria-label="3. 图存储和查询">3. 图存储和查询</a></li></ul></li><li><a href=#%e6%9e%84%e5%bb%ba%e7%9f%a5%e8%af%86%e5%9b%be%e8%b0%b1%e7%9a%84%e5%b7%a5%e4%bd%9c%e6%b5%81%e7%a8%8b aria-label=构建知识图谱的工作流程>构建知识图谱的工作流程</a></li><li><a href=#%e5%ae%9e%e9%99%85%e4%bb%a3%e7%a0%81%e7%a4%ba%e4%be%8b aria-label=实际代码示例>实际代码示例</a><ul><li><a href=#1-%e5%9f%ba%e7%a1%80%e8%ae%be%e7%bd%ae aria-label="1. 基础设置">1. 基础设置</a></li><li><a href=#2-%e4%bb%8e%e6%96%87%e6%9c%ac%e6%9e%84%e5%bb%ba%e7%9f%a5%e8%af%86%e5%9b%be%e8%b0%b1 aria-label="2. 从文本构建知识图谱">2. 从文本构建知识图谱</a></li><li><a href=#3-%e6%9f%a5%e8%af%a2%e7%9f%a5%e8%af%86%e5%9b%be%e8%b0%b1 aria-label="3. 查询知识图谱">3. 查询知识图谱</a></li></ul></li><li><a href=#%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af%e5%9b%be%e8%a7%a3 aria-label=应用场景图解>应用场景图解</a><ul><li><a href=#1-%e6%99%ba%e8%83%bd%e9%97%ae%e7%ad%94%e7%b3%bb%e7%bb%9f aria-label="1. 智能问答系统">1. 智能问答系统</a></li><li><a href=#2-%e7%9f%a5%e8%af%86%e5%8f%91%e7%8e%b0%e4%b8%8e%e6%8e%a8%e7%90%86 aria-label="2. 知识发现与推理">2. 知识发现与推理</a></li><li><a href=#3-%e5%86%85%e5%ae%b9%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f aria-label="3. 内容推荐系统">3. 内容推荐系统</a></li></ul></li><li><a href=#%e9%ab%98%e7%ba%a7%e7%94%a8%e6%b3%95%e5%a4%8d%e6%9d%82%e7%9f%a5%e8%af%86%e5%9b%be%e8%b0%b1 aria-label=高级用法：复杂知识图谱>高级用法：复杂知识图谱</a><ul><li><a href=#1-%e5%a4%9a%e6%ba%90%e6%95%b0%e6%8d%ae%e9%9b%86%e6%88%90 aria-label="1. 多源数据集成">1. 多源数据集成</a></li><li><a href=#2-%e5%9b%be%e5%bc%95%e5%af%bc%e7%9a%84%e6%8e%a8%e7%90%86%e5%a2%9e%e5%bc%ba aria-label="2. 图引导的推理增强">2. 图引导的推理增强</a></li></ul></li><li><a href=#%e4%bb%a3%e7%a0%81%e5%ae%9e%e7%8e%b0%e5%a4%8d%e6%9d%82%e6%9f%a5%e8%af%a2%e7%a4%ba%e4%be%8b aria-label=代码实现：复杂查询示例>代码实现：复杂查询示例</a></li><li><a href=#%e6%9c%80%e4%bd%b3%e5%ae%9e%e8%b7%b5%e4%b8%8e%e4%bc%98%e5%8c%96%e6%8a%80%e5%b7%a7 aria-label=最佳实践与优化技巧>最佳实践与优化技巧</a><ul><li><a href=#1-%e5%ae%9e%e4%bd%93%e5%92%8c%e5%85%b3%e7%b3%bb%e5%ae%9a%e4%b9%89%e7%ad%96%e7%95%a5 aria-label="1. 实体和关系定义策略">1. 实体和关系定义策略</a></li><li><a href=#2-%e6%80%a7%e8%83%bd%e4%bc%98%e5%8c%96%e6%8a%80%e5%b7%a7 aria-label="2. 性能优化技巧">2. 性能优化技巧</a></li></ul></li><li><a href=#%e5%ae%8c%e6%95%b4%e5%b7%a5%e4%bd%9c%e6%b5%81%e4%bb%8e%e6%96%87%e6%a1%a3%e5%88%b0%e6%99%ba%e8%83%bd%e5%ba%94%e7%94%a8 aria-label=完整工作流：从文档到智能应用>完整工作流：从文档到智能应用</a></li><li><a href=#%e5%ae%9e%e9%99%85%e6%a1%88%e4%be%8b%e7%a0%94%e7%a9%b6%e9%a2%86%e5%9f%9f%e7%9f%a5%e8%af%86%e5%9b%be%e8%b0%b1 aria-label=实际案例：研究领域知识图谱>实际案例：研究领域知识图谱</a></li><li><a href=#%e6%80%bb%e7%bb%93 aria-label=总结>总结</a></li><li><a href=#%e6%89%a9%e5%b1%95%e9%98%85%e8%af%bb aria-label=扩展阅读>扩展阅读</a></li></ul></div></details></div><div class=post-content><h2 id=引言>引言<a hidden class=anchor aria-hidden=true href=#引言>#</a></h2><p>在人工智能和大语言模型(LLM)的应用中，知识的表示与组织方式直接影响系统的推理能力和智能水平。<strong>LangChain Graph</strong> 作为LangChain生态系统中的重要组件，提供了一套强大的工具，使开发者能够轻松地从文本中提取结构化知识，构建知识图谱，并基于图进行复杂推理。本文将深入探讨LangChain Graph的概念、工作原理、应用场景以及实践技巧，帮助您全面理解和应用这一强大工具。</p><h2 id=知识图谱与langchain-graph基础>知识图谱与LangChain Graph基础<a hidden class=anchor aria-hidden=true href=#知识图谱与langchain-graph基础>#</a></h2><h3 id=什么是知识图谱>什么是知识图谱？<a hidden class=anchor aria-hidden=true href=#什么是知识图谱>#</a></h3><p>知识图谱(Knowledge Graph)是一种结构化数据模型，用于表示实体(Entities)之间的关系(Relations)。它以图的形式组织信息，其中：</p><ul><li><strong>节点(Nodes)</strong>：代表实体或概念</li><li><strong>边(Edges)</strong>：代表实体间的关系</li></ul><pre tabindex=0><code class=language-mermaid data-lang=mermaid>graph LR
    A[&#34;艾伦·图灵&#34;] --&gt;|&#34;发明&#34;| B[&#34;图灵机&#34;]
    A --&gt;|&#34;出生于&#34;| C[&#34;英国&#34;]
    A --&gt;|&#34;被誉为&#34;| D[&#34;计算机科学之父&#34;]
    B --&gt;|&#34;是&#34;| E[&#34;理论计算模型&#34;]
</code></pre><h3 id=langchain-graph的定义与价值>LangChain Graph的定义与价值<a hidden class=anchor aria-hidden=true href=#langchain-graph的定义与价值>#</a></h3><p>LangChain Graph是LangChain框架中专注于知识图谱构建、存储和查询的模块集合。它将LLM的自然语言处理能力与图数据库的结构化表示结合，实现了：</p><ol><li>自动从文本中提取实体和关系</li><li>构建和维护知识图谱</li><li>基于图结构进行复杂查询和推理</li><li>增强LLM应用的上下文理解和回答质量</li></ol><h2 id=langchain-graph架构>LangChain Graph架构<a hidden class=anchor aria-hidden=true href=#langchain-graph架构>#</a></h2><p>LangChain Graph的整体架构可以通过以下图示来理解：</p><pre tabindex=0><code class=language-mermaid data-lang=mermaid>flowchart TB
    subgraph &#34;输入层&#34;
        A[&#34;文本文档&#34;] --&gt; B[&#34;网页内容&#34;]
        C[&#34;结构化数据&#34;] --&gt; D[&#34;用户查询&#34;]
    end
    
    subgraph &#34;处理层&#34;
        E[&#34;实体提取&lt;br&gt;EntityExtractor&#34;]
        F[&#34;关系提取&lt;br&gt;RelationExtractor&#34;]
        G[&#34;知识图谱构建&lt;br&gt;KnowledgeGraphCreator&#34;]
    end
    
    subgraph &#34;存储层&#34;
        H[&#34;图数据库&lt;br&gt;Neo4j/NetworkX&#34;]
        I[&#34;向量存储&lt;br&gt;VectorStores&#34;]
    end
    
    subgraph &#34;应用层&#34;
        J[&#34;图查询&lt;br&gt;GraphQuery&#34;]
        K[&#34;图推理&lt;br&gt;GraphReasoning&#34;]
        L[&#34;QA系统&lt;br&gt;GraphQAChain&#34;]
    end
    
    A --&gt; E
    B --&gt; E
    C --&gt; F
    D --&gt; F
    E --&gt; G
    F --&gt; G
    G --&gt; H
    G --&gt; I
    H --&gt; J
    H --&gt; K
    I --&gt; L
</code></pre><h2 id=核心组件详解>核心组件详解<a hidden class=anchor aria-hidden=true href=#核心组件详解>#</a></h2><h3 id=1-实体和关系提取器>1. 实体和关系提取器<a hidden class=anchor aria-hidden=true href=#1-实体和关系提取器>#</a></h3><p>这些组件负责从文本中识别实体和它们之间的关系：</p><pre tabindex=0><code class=language-mermaid data-lang=mermaid>sequenceDiagram
    participant Text as 文本输入
    participant LLM as 大语言模型
    participant EE as EntityExtractor
    participant RE as RelationExtractor
    participant KG as 知识图谱
    
    Text-&gt;&gt;LLM: 发送文本
    LLM-&gt;&gt;EE: 提取实体
    EE-&gt;&gt;RE: 传递识别的实体
    RE-&gt;&gt;LLM: 使用LLM确定实体间关系
    RE-&gt;&gt;KG: 构建三元组(主体-关系-客体)
</code></pre><h3 id=2-知识图谱构建>2. 知识图谱构建<a hidden class=anchor aria-hidden=true href=#2-知识图谱构建>#</a></h3><pre tabindex=0><code class=language-mermaid data-lang=mermaid>flowchart LR
    A[&#34;文本&#34;] --&gt; B{&#34;实体提取&#34;}
    B --&gt; |&#34;人物/地点/组织等&#34;| C[&#34;实体列表&#34;]
    C --&gt; D{&#34;关系提取&#34;}
    D --&gt; |&#34;分析实体间关联&#34;| E[&#34;三元组集合&#34;]
    E --&gt; F[&#34;知识图谱构建器&#34;]
    F --&gt; G[(&#34;图数据库&#34;)]
    F --&gt; H[&#34;内存图&#34;]
</code></pre><h3 id=3-图存储和查询>3. 图存储和查询<a hidden class=anchor aria-hidden=true href=#3-图存储和查询>#</a></h3><p>LangChain Graph支持多种图存储方式：</p><pre tabindex=0><code class=language-mermaid data-lang=mermaid>graph TD
    A[&#34;知识图谱数据&#34;] --&gt; B{&#34;存储方式&#34;}
    B --&gt;|&#34;内存存储&#34;| C[&#34;NetworkX&#34;]
    B --&gt;|&#34;图数据库&#34;| D[&#34;Neo4j&#34;]
    B --&gt;|&#34;向量数据库&#34;| E[&#34;Chroma/FAISS等&#34;]
    
    C --&gt; F{&#34;查询方式&#34;}
    D --&gt; F
    E --&gt; F
    F --&gt;|&#34;Cypher查询&#34;| G[&#34;Neo4j查询&#34;]
    F --&gt;|&#34;图算法&#34;| H[&#34;NetworkX算法&#34;]
    F --&gt;|&#34;自然语言&#34;| I[&#34;LLM辅助查询&#34;]
</code></pre><h2 id=构建知识图谱的工作流程>构建知识图谱的工作流程<a hidden class=anchor aria-hidden=true href=#构建知识图谱的工作流程>#</a></h2><p>以下是使用LangChain Graph构建知识图谱的完整流程：</p><pre tabindex=0><code class=language-mermaid data-lang=mermaid>flowchart TD
    A[&#34;准备文本数据&#34;] --&gt; B[&#34;文本处理和分块&#34;]
    B --&gt; C[&#34;实体提取&#34;]
    C --&gt; D[&#34;关系识别&#34;]
    D --&gt; E[&#34;三元组生成&#34;]
    E --&gt; F[&#34;图构建和存储&#34;]
    F --&gt; G[&#34;图查询和利用&#34;]
    
    subgraph &#34;文本处理阶段&#34;
        A
        B
    end
    
    subgraph &#34;信息提取阶段&#34;
        C
        D
        E
    end
    
    subgraph &#34;图构建阶段&#34;
        F
    end
    
    subgraph &#34;应用阶段&#34;
        G
    end
</code></pre><h2 id=实际代码示例>实际代码示例<a hidden class=anchor aria-hidden=true href=#实际代码示例>#</a></h2><p>让我们通过实际代码来理解LangChain Graph的使用方法。</p><h3 id=1-基础设置>1. 基础设置<a hidden class=anchor aria-hidden=true href=#1-基础设置>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-javascript data-lang=javascript><span style=display:flex><span><span style=color:#75715e>// 导入必要的包
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>import</span> { <span style=color:#a6e22e>ChatOpenAI</span> } <span style=color:#a6e22e>from</span> <span style=color:#e6db74>&#34;@langchain/openai&#34;</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>import</span> { <span style=color:#a6e22e>EntityExtractor</span>, <span style=color:#a6e22e>RelationExtractor</span>, <span style=color:#a6e22e>KnowledgeGraph</span> } <span style=color:#a6e22e>from</span> <span style=color:#e6db74>&#34;langchain/graphs&#34;</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>import</span> { <span style=color:#a6e22e>Neo4jGraph</span> } <span style=color:#a6e22e>from</span> <span style=color:#e6db74>&#34;langchain/graphs/neo4j_graph&#34;</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>import</span> { <span style=color:#a6e22e>Document</span> } <span style=color:#a6e22e>from</span> <span style=color:#e6db74>&#34;langchain/document&#34;</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// 初始化LLM
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>const</span> <span style=color:#a6e22e>llm</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> <span style=color:#a6e22e>ChatOpenAI</span>({
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>temperature</span><span style=color:#f92672>:</span> <span style=color:#ae81ff>0</span>,
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>model</span><span style=color:#f92672>:</span> <span style=color:#e6db74>&#34;gpt-4-turbo&#34;</span>
</span></span><span style=display:flex><span>});
</span></span></code></pre></div><h3 id=2-从文本构建知识图谱>2. 从文本构建知识图谱<a hidden class=anchor aria-hidden=true href=#2-从文本构建知识图谱>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-javascript data-lang=javascript><span style=display:flex><span><span style=color:#75715e>// 准备文本
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>const</span> <span style=color:#a6e22e>text</span> <span style=color:#f92672>=</span> <span style=color:#e6db74>`
</span></span></span><span style=display:flex><span><span style=color:#e6db74>艾伦·图灵于1912年出生于英国伦敦。他是计算机科学和人工智能的先驱。
</span></span></span><span style=display:flex><span><span style=color:#e6db74>图灵在剑桥大学国王学院和普林斯顿大学学习。他于1936年发表了关于图灵机的论文。
</span></span></span><span style=display:flex><span><span style=color:#e6db74>在第二次世界大战期间，图灵在英国密码破译中心布莱切利园工作，成功破解了德国的英格玛密码。
</span></span></span><span style=display:flex><span><span style=color:#e6db74>`</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// 创建文档
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>const</span> <span style=color:#a6e22e>docs</span> <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>new</span> <span style=color:#a6e22e>Document</span>({ <span style=color:#a6e22e>pageContent</span><span style=color:#f92672>:</span> <span style=color:#a6e22e>text</span> })
</span></span><span style=display:flex><span>];
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// 初始化Neo4j图数据库连接
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>const</span> <span style=color:#a6e22e>graph</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> <span style=color:#a6e22e>Neo4jGraph</span>.<span style=color:#a6e22e>initialize</span>({
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>url</span><span style=color:#f92672>:</span> <span style=color:#e6db74>&#34;neo4j://localhost:7687&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>username</span><span style=color:#f92672>:</span> <span style=color:#e6db74>&#34;neo4j&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>password</span><span style=color:#f92672>:</span> <span style=color:#e6db74>&#34;password&#34;</span>
</span></span><span style=display:flex><span>});
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// 创建知识图谱构建器
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>const</span> <span style=color:#a6e22e>kg</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> <span style=color:#a6e22e>KnowledgeGraph</span>({
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>llm</span>,
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>entityExtractor</span><span style=color:#f92672>:</span> <span style=color:#66d9ef>new</span> <span style=color:#a6e22e>EntityExtractor</span>({ <span style=color:#a6e22e>llm</span> }),
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>relationExtractor</span><span style=color:#f92672>:</span> <span style=color:#66d9ef>new</span> <span style=color:#a6e22e>RelationExtractor</span>({ <span style=color:#a6e22e>llm</span> })
</span></span><span style=display:flex><span>});
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// 从文本构建知识图谱
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>await</span> <span style=color:#a6e22e>kg</span>.<span style=color:#a6e22e>buildFromDocuments</span>(<span style=color:#a6e22e>docs</span>, { <span style=color:#a6e22e>graph</span> });
</span></span></code></pre></div><h3 id=3-查询知识图谱>3. 查询知识图谱<a hidden class=anchor aria-hidden=true href=#3-查询知识图谱>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-javascript data-lang=javascript><span style=display:flex><span><span style=color:#75715e>// Cypher查询
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>const</span> <span style=color:#a6e22e>cypherQuery</span> <span style=color:#f92672>=</span> <span style=color:#e6db74>`
</span></span></span><span style=display:flex><span><span style=color:#e6db74>MATCH (p:Person {name: &#39;艾伦·图灵&#39;})-[r]-&gt;(o)
</span></span></span><span style=display:flex><span><span style=color:#e6db74>RETURN p, r, o
</span></span></span><span style=display:flex><span><span style=color:#e6db74>`</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>const</span> <span style=color:#a6e22e>result</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> <span style=color:#a6e22e>graph</span>.<span style=color:#a6e22e>query</span>(<span style=color:#a6e22e>cypherQuery</span>);
</span></span><span style=display:flex><span><span style=color:#a6e22e>console</span>.<span style=color:#a6e22e>log</span>(<span style=color:#a6e22e>result</span>);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// 自然语言查询
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>import</span> { <span style=color:#a6e22e>GraphCypherQAChain</span> } <span style=color:#a6e22e>from</span> <span style=color:#e6db74>&#34;langchain/chains&#34;</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>const</span> <span style=color:#a6e22e>chain</span> <span style=color:#f92672>=</span> <span style=color:#a6e22e>GraphCypherQAChain</span>.<span style=color:#a6e22e>fromLLM</span>({
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>llm</span>,
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>graph</span>,
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>verbose</span><span style=color:#f92672>:</span> <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>});
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>const</span> <span style=color:#a6e22e>answer</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> <span style=color:#a6e22e>chain</span>.<span style=color:#a6e22e>invoke</span>({
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>query</span><span style=color:#f92672>:</span> <span style=color:#e6db74>&#34;艾伦·图灵在哪里上的大学？&#34;</span>
</span></span><span style=display:flex><span>});
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>console</span>.<span style=color:#a6e22e>log</span>(<span style=color:#a6e22e>answer</span>.<span style=color:#a6e22e>text</span>);
</span></span></code></pre></div><h2 id=应用场景图解>应用场景图解<a hidden class=anchor aria-hidden=true href=#应用场景图解>#</a></h2><h3 id=1-智能问答系统>1. 智能问答系统<a hidden class=anchor aria-hidden=true href=#1-智能问答系统>#</a></h3><pre tabindex=0><code class=language-mermaid data-lang=mermaid>sequenceDiagram
    actor User as 用户
    participant QA as QA系统
    participant LLM as 大语言模型
    participant KG as 知识图谱
    
    User-&gt;&gt;QA: 提问
    QA-&gt;&gt;LLM: 分析问题
    LLM-&gt;&gt;QA: 确定查询意图
    QA-&gt;&gt;KG: 构建图查询
    KG-&gt;&gt;QA: 返回相关子图
    QA-&gt;&gt;LLM: 基于子图生成回答
    LLM-&gt;&gt;QA: 生成回答
    QA-&gt;&gt;User: 呈现回答
</code></pre><h3 id=2-知识发现与推理>2. 知识发现与推理<a hidden class=anchor aria-hidden=true href=#2-知识发现与推理>#</a></h3><pre tabindex=0><code class=language-mermaid data-lang=mermaid>graph TD
    A[&#34;文档集合&#34;] --&gt; B[&#34;知识图谱&#34;]
    B --&gt; C{&#34;路径分析&#34;}
    B --&gt; D{&#34;社区发现&#34;}
    B --&gt; E{&#34;关系推断&#34;}
    
    C --&gt; F[&#34;隐藏关联发现&#34;]
    D --&gt; G[&#34;领域聚类&#34;]
    E --&gt; H[&#34;新知识产生&#34;]
    
    F --&gt; I[&#34;知识增强的应用&#34;]
    G --&gt; I
    H --&gt; I
</code></pre><h3 id=3-内容推荐系统>3. 内容推荐系统<a hidden class=anchor aria-hidden=true href=#3-内容推荐系统>#</a></h3><pre tabindex=0><code class=language-mermaid data-lang=mermaid>flowchart LR
    A[&#34;用户&#34;] --&gt; B{&#34;兴趣提取&#34;}
    B --&gt; C[&#34;用户实体图&#34;]
    
    D[&#34;内容库&#34;] --&gt; E{&#34;内容分析&#34;}
    E --&gt; F[&#34;内容知识图&#34;]
    
    C --&gt; G{&#34;图匹配算法&#34;}
    F --&gt; G
    G --&gt; H[&#34;个性化推荐&#34;]
    H --&gt; A
</code></pre><h2 id=高级用法复杂知识图谱>高级用法：复杂知识图谱<a hidden class=anchor aria-hidden=true href=#高级用法复杂知识图谱>#</a></h2><h3 id=1-多源数据集成>1. 多源数据集成<a hidden class=anchor aria-hidden=true href=#1-多源数据集成>#</a></h3><pre tabindex=0><code class=language-mermaid data-lang=mermaid>flowchart TB
    A1[&#34;文本文档&#34;] --&gt; B[&#34;数据预处理&#34;]
    A2[&#34;结构化数据&#34;] --&gt; B
    A3[&#34;网页内容&#34;] --&gt; B
    A4[&#34;APIs&#34;] --&gt; B
    
    B --&gt; C{&#34;实体统一&#34;}
    C --&gt; D{&#34;关系提取&#34;}
    D --&gt; E[&#34;图构建&#34;]
    
    E --&gt; F{&#34;图增强&#34;}
    F --&gt; G[&#34;实体链接&#34;]
    F --&gt; H[&#34;异构合并&#34;]
    F --&gt; I[&#34;冲突消解&#34;]
    
    G --&gt; J[&#34;完整知识图谱&#34;]
    H --&gt; J
    I --&gt; J
</code></pre><h3 id=2-图引导的推理增强>2. 图引导的推理增强<a hidden class=anchor aria-hidden=true href=#2-图引导的推理增强>#</a></h3><pre tabindex=0><code class=language-mermaid data-lang=mermaid>flowchart LR
    A[&#34;用户查询&#34;] --&gt; B{&#34;分析意图&#34;}
    B --&gt; C[&#34;知识图谱查询&#34;]
    C --&gt; D[&#34;子图检索&#34;]
    
    D --&gt; E{&#34;构建提示&#34;}
    E --&gt; F[&#34;边界约束&#34;]
    E --&gt; G[&#34;路径引导&#34;]
    E --&gt; H[&#34;属性填充&#34;]
    
    F --&gt; I[&#34;增强提示&#34;]
    G --&gt; I
    H --&gt; I
    I --&gt; J[&#34;LLM推理&#34;]
    J --&gt; K[&#34;精确回答&#34;]
</code></pre><h2 id=代码实现复杂查询示例>代码实现：复杂查询示例<a hidden class=anchor aria-hidden=true href=#代码实现复杂查询示例>#</a></h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-javascript data-lang=javascript><span style=display:flex><span><span style=color:#75715e>// 创建自定义实体和关系提取器
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>const</span> <span style=color:#a6e22e>entityExtractor</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> <span style=color:#a6e22e>EntityExtractor</span>({ 
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>llm</span>,
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>allowedEntityTypes</span><span style=color:#f92672>:</span> [<span style=color:#e6db74>&#34;Person&#34;</span>, <span style=color:#e6db74>&#34;Organization&#34;</span>, <span style=color:#e6db74>&#34;Location&#34;</span>, <span style=color:#e6db74>&#34;Event&#34;</span>, <span style=color:#e6db74>&#34;Work&#34;</span>, <span style=color:#e6db74>&#34;Concept&#34;</span>],
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>contextWindowSize</span><span style=color:#f92672>:</span> <span style=color:#ae81ff>3000</span>
</span></span><span style=display:flex><span>});
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>const</span> <span style=color:#a6e22e>relationExtractor</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> <span style=color:#a6e22e>RelationExtractor</span>({
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>llm</span>,
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>relationExtractionPrompt</span><span style=color:#f92672>:</span> <span style=color:#e6db74>`识别以下文本中实体之间的关系，并以(主体, 关系, 客体)的形式返回。注意关系应该是具体且有意义的动词短语。`</span>,
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>validateRelations</span><span style=color:#f92672>:</span> <span style=color:#66d9ef>true</span>,
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>maxRelationsPerEntityPair</span><span style=color:#f92672>:</span> <span style=color:#ae81ff>3</span>
</span></span><span style=display:flex><span>});
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// 实现增量式图构建
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>async</span> <span style=color:#66d9ef>function</span> <span style=color:#a6e22e>incrementalGraphBuild</span>(<span style=color:#a6e22e>documents</span>, <span style=color:#a6e22e>graph</span>) {
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>kg</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> <span style=color:#a6e22e>KnowledgeGraph</span>({
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>llm</span>,
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>entityExtractor</span>,
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>relationExtractor</span>
</span></span><span style=display:flex><span>  });
</span></span><span style=display:flex><span>  
</span></span><span style=display:flex><span>  <span style=color:#75715e>// 批处理文档
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>  <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>batchSize</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>5</span>;
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>let</span> <span style=color:#a6e22e>i</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; <span style=color:#a6e22e>i</span> <span style=color:#f92672>&lt;</span> <span style=color:#a6e22e>documents</span>.<span style=color:#a6e22e>length</span>; <span style=color:#a6e22e>i</span> <span style=color:#f92672>+=</span> <span style=color:#a6e22e>batchSize</span>) {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>batch</span> <span style=color:#f92672>=</span> <span style=color:#a6e22e>documents</span>.<span style=color:#a6e22e>slice</span>(<span style=color:#a6e22e>i</span>, <span style=color:#a6e22e>i</span> <span style=color:#f92672>+</span> <span style=color:#a6e22e>batchSize</span>);
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>console</span>.<span style=color:#a6e22e>log</span>(<span style=color:#e6db74>`处理批次 </span><span style=color:#e6db74>${</span>Math.<span style=color:#a6e22e>floor</span>(<span style=color:#a6e22e>i</span><span style=color:#f92672>/</span><span style=color:#a6e22e>batchSize</span>) <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span><span style=color:#e6db74>}</span><span style=color:#e6db74>/</span><span style=color:#e6db74>${</span>Math.<span style=color:#a6e22e>ceil</span>(<span style=color:#a6e22e>documents</span>.<span style=color:#a6e22e>length</span><span style=color:#f92672>/</span><span style=color:#a6e22e>batchSize</span>)<span style=color:#e6db74>}</span><span style=color:#e6db74>`</span>);
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>await</span> <span style=color:#a6e22e>kg</span>.<span style=color:#a6e22e>buildFromDocuments</span>(<span style=color:#a6e22e>batch</span>, { 
</span></span><span style=display:flex><span>      <span style=color:#a6e22e>graph</span>,
</span></span><span style=display:flex><span>      <span style=color:#a6e22e>mergeEntities</span><span style=color:#f92672>:</span> <span style=color:#66d9ef>true</span>  <span style=color:#75715e>// 合并同名实体
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    });
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>  
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>return</span> <span style=color:#a6e22e>graph</span>;
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// 复杂查询示例
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>async</span> <span style=color:#66d9ef>function</span> <span style=color:#a6e22e>complexGraphQuery</span>(<span style=color:#a6e22e>graph</span>, <span style=color:#a6e22e>query</span>) {
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>chain</span> <span style=color:#f92672>=</span> <span style=color:#a6e22e>GraphCypherQAChain</span>.<span style=color:#a6e22e>fromLLM</span>({
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>llm</span><span style=color:#f92672>:</span> <span style=color:#66d9ef>new</span> <span style=color:#a6e22e>ChatOpenAI</span>({ <span style=color:#a6e22e>model</span><span style=color:#f92672>:</span> <span style=color:#e6db74>&#34;gpt-4&#34;</span>, <span style=color:#a6e22e>temperature</span><span style=color:#f92672>:</span> <span style=color:#ae81ff>0</span> }),
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>graph</span>,
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>returnDirect</span><span style=color:#f92672>:</span> <span style=color:#66d9ef>false</span>,  <span style=color:#75715e>// 不直接返回Cypher查询结果
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#a6e22e>cypherPrompt</span><span style=color:#f92672>:</span> <span style=color:#e6db74>`根据以下问题，生成适当的Cypher查询以从知识图谱中检索相关信息。考虑使用图算法和复杂模式匹配。`</span>
</span></span><span style=display:flex><span>  });
</span></span><span style=display:flex><span>  
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>return</span> <span style=color:#a6e22e>chain</span>.<span style=color:#a6e22e>invoke</span>({ <span style=color:#a6e22e>query</span> });
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h2 id=最佳实践与优化技巧>最佳实践与优化技巧<a hidden class=anchor aria-hidden=true href=#最佳实践与优化技巧>#</a></h2><h3 id=1-实体和关系定义策略>1. 实体和关系定义策略<a hidden class=anchor aria-hidden=true href=#1-实体和关系定义策略>#</a></h3><pre tabindex=0><code class=language-mermaid data-lang=mermaid>graph TD
    A[&#34;定义实体类型&#34;] --&gt; B{&#34;选择粒度&#34;}
    B --&gt; |&#34;粗粒度&#34;| C[&#34;主要类别&lt;br&gt;如人/地点/组织&#34;]
    B --&gt; |&#34;细粒度&#34;| D[&#34;详细类别&lt;br&gt;如政治家/城市/科技公司&#34;]
    
    C --&gt; E{&#34;关系定义&#34;}
    D --&gt; E
    E --&gt; |&#34;语义明确&#34;| F[&#34;精确关系&lt;br&gt;如&#39;创立&#39;而非&#39;关联&#39;&#34;]
    E --&gt; |&#34;一致性&#34;| G[&#34;标准化关系名称&#34;]
    
    F --&gt; H[&#34;图模式设计&#34;]
    G --&gt; H
    H --&gt; I[&#34;属性与关系区分&#34;]
    H --&gt; J[&#34;多重关系处理&#34;]
</code></pre><h3 id=2-性能优化技巧>2. 性能优化技巧<a hidden class=anchor aria-hidden=true href=#2-性能优化技巧>#</a></h3><p>对于大规模知识图谱，以下优化技巧至关重要：</p><pre tabindex=0><code class=language-mermaid data-lang=mermaid>flowchart TD
    A[&#34;性能优化&#34;] --&gt; B{&#34;处理大型文档&#34;}
    A --&gt; C{&#34;查询优化&#34;}
    A --&gt; D{&#34;存储策略&#34;}
    
    B --&gt; B1[&#34;分块处理&#34;]
    B --&gt; B2[&#34;并行提取&#34;]
    B --&gt; B3[&#34;批量处理&#34;]
    
    C --&gt; C1[&#34;查询缓存&#34;]
    C --&gt; C2[&#34;索引优化&#34;]
    C --&gt; C3[&#34;查询重写&#34;]
    
    D --&gt; D1[&#34;图数据分区&#34;]
    D --&gt; D2[&#34;冷热数据分离&#34;]
    D --&gt; D3[&#34;增量更新&#34;]
</code></pre><h2 id=完整工作流从文档到智能应用>完整工作流：从文档到智能应用<a hidden class=anchor aria-hidden=true href=#完整工作流从文档到智能应用>#</a></h2><p>下面是一个完整的工作流，展示了如何从文档构建知识图谱并应用到实际应用场景：</p><pre tabindex=0><code class=language-mermaid data-lang=mermaid>flowchart TD
    subgraph &#34;数据准备&#34;
        A1[&#34;文档收集&#34;] --&gt; A2[&#34;文档清洗&#34;]
        A2 --&gt; A3[&#34;文档分块&#34;]
    end
    
    subgraph &#34;知识提取&#34;
        A3 --&gt; B1[&#34;实体识别&#34;]
        B1 --&gt; B2[&#34;关系提取&#34;]
        B2 --&gt; B3[&#34;属性提取&#34;]
    end
    
    subgraph &#34;图构建与存储&#34;
        B3 --&gt; C1[&#34;三元组生成&#34;]
        C1 --&gt; C2[&#34;图构建&#34;]
        C2 --&gt; C3[&#34;图存储&#34;]
    end
    
    subgraph &#34;图增强&#34;
        C3 --&gt; D1[&#34;实体链接&#34;]
        D1 --&gt; D2[&#34;推理扩展&#34;]
        D2 --&gt; D3[&#34;图验证&#34;]
    end
    
    subgraph &#34;应用集成&#34;
        D3 --&gt; E1[&#34;问答系统&#34;]
        D3 --&gt; E2[&#34;搜索增强&#34;]
        D3 --&gt; E3[&#34;内容推荐&#34;]
        D3 --&gt; E4[&#34;决策支持&#34;]
    end
</code></pre><h2 id=实际案例研究领域知识图谱>实际案例：研究领域知识图谱<a hidden class=anchor aria-hidden=true href=#实际案例研究领域知识图谱>#</a></h2><p>以下是一个构建学术研究领域知识图谱的完整示例：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-javascript data-lang=javascript><span style=display:flex><span><span style=color:#75715e>// 示例：构建AI研究领域知识图谱
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>import</span> { <span style=color:#a6e22e>OpenAI</span> } <span style=color:#a6e22e>from</span> <span style=color:#e6db74>&#34;@langchain/openai&#34;</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>import</span> { <span style=color:#a6e22e>RecursiveCharacterTextSplitter</span> } <span style=color:#a6e22e>from</span> <span style=color:#e6db74>&#34;langchain/text_splitter&#34;</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>import</span> { <span style=color:#a6e22e>EntityExtractor</span>, <span style=color:#a6e22e>RelationExtractor</span>, <span style=color:#a6e22e>KnowledgeGraph</span> } <span style=color:#a6e22e>from</span> <span style=color:#e6db74>&#34;langchain/graphs&#34;</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>import</span> { <span style=color:#a6e22e>Neo4jGraph</span> } <span style=color:#a6e22e>from</span> <span style=color:#e6db74>&#34;langchain/graphs/neo4j_graph&#34;</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>import</span> { <span style=color:#a6e22e>GraphRAGRetriever</span> } <span style=color:#a6e22e>from</span> <span style=color:#e6db74>&#34;langchain/retrievers/graph_rag&#34;</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>import</span> { <span style=color:#a6e22e>RetrievalQAChain</span> } <span style=color:#a6e22e>from</span> <span style=color:#e6db74>&#34;langchain/chains&#34;</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>import</span> { <span style=color:#a6e22e>Document</span> } <span style=color:#a6e22e>from</span> <span style=color:#e6db74>&#34;langchain/document&#34;</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>async</span> <span style=color:#66d9ef>function</span> <span style=color:#a6e22e>buildResearchGraph</span>(<span style=color:#a6e22e>papers</span>, <span style=color:#a6e22e>graph</span>) {
</span></span><span style=display:flex><span>  <span style=color:#75715e>// 初始化LLM
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>  <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>llm</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> <span style=color:#a6e22e>ChatOpenAI</span>({
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>temperature</span><span style=color:#f92672>:</span> <span style=color:#ae81ff>0</span>,
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>model</span><span style=color:#f92672>:</span> <span style=color:#e6db74>&#34;gpt-4&#34;</span>
</span></span><span style=display:flex><span>  });
</span></span><span style=display:flex><span>  
</span></span><span style=display:flex><span>  <span style=color:#75715e>// 自定义实体提取器
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>  <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>entityExtractor</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> <span style=color:#a6e22e>EntityExtractor</span>({
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>llm</span>,
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>allowedEntityTypes</span><span style=color:#f92672>:</span> [
</span></span><span style=display:flex><span>      <span style=color:#e6db74>&#34;Researcher&#34;</span>, <span style=color:#e6db74>&#34;Paper&#34;</span>, <span style=color:#e6db74>&#34;University&#34;</span>, <span style=color:#e6db74>&#34;Conference&#34;</span>, 
</span></span><span style=display:flex><span>      <span style=color:#e6db74>&#34;ResearchField&#34;</span>, <span style=color:#e6db74>&#34;Method&#34;</span>, <span style=color:#e6db74>&#34;Algorithm&#34;</span>, <span style=color:#e6db74>&#34;Dataset&#34;</span>
</span></span><span style=display:flex><span>    ]
</span></span><span style=display:flex><span>  });
</span></span><span style=display:flex><span>  
</span></span><span style=display:flex><span>  <span style=color:#75715e>// 自定义关系提取器
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>  <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>relationExtractor</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> <span style=color:#a6e22e>RelationExtractor</span>({
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>llm</span>,
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>validateRelations</span><span style=color:#f92672>:</span> <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>  });
</span></span><span style=display:flex><span>  
</span></span><span style=display:flex><span>  <span style=color:#75715e>// 初始化知识图谱构建器
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>  <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>kg</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> <span style=color:#a6e22e>KnowledgeGraph</span>({
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>llm</span>,
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>entityExtractor</span>,
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>relationExtractor</span>
</span></span><span style=display:flex><span>  });
</span></span><span style=display:flex><span>  
</span></span><span style=display:flex><span>  <span style=color:#75715e>// 文本分割
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>  <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>textSplitter</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> <span style=color:#a6e22e>RecursiveCharacterTextSplitter</span>({
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>chunkSize</span><span style=color:#f92672>:</span> <span style=color:#ae81ff>2000</span>,
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>chunkOverlap</span><span style=color:#f92672>:</span> <span style=color:#ae81ff>200</span>
</span></span><span style=display:flex><span>  });
</span></span><span style=display:flex><span>  
</span></span><span style=display:flex><span>  <span style=color:#75715e>// 处理每篇论文
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>  <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>const</span> <span style=color:#a6e22e>paper</span> <span style=color:#66d9ef>of</span> <span style=color:#a6e22e>papers</span>) {
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>console</span>.<span style=color:#a6e22e>log</span>(<span style=color:#e6db74>`处理论文: </span><span style=color:#e6db74>${</span><span style=color:#a6e22e>paper</span>.<span style=color:#a6e22e>title</span><span style=color:#e6db74>}</span><span style=color:#e6db74>`</span>);
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e>// 创建文档
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>text</span> <span style=color:#f92672>=</span> <span style=color:#e6db74>`标题: </span><span style=color:#e6db74>${</span><span style=color:#a6e22e>paper</span>.<span style=color:#a6e22e>title</span><span style=color:#e6db74>}</span><span style=color:#e6db74>\n作者: </span><span style=color:#e6db74>${</span><span style=color:#a6e22e>paper</span>.<span style=color:#a6e22e>authors</span>.<span style=color:#a6e22e>join</span>(<span style=color:#e6db74>&#39;, &#39;</span>)<span style=color:#e6db74>}</span><span style=color:#e6db74>\n摘要: </span><span style=color:#e6db74>${</span><span style=color:#a6e22e>paper</span>.<span style=color:#66d9ef>abstract</span><span style=color:#e6db74>}</span><span style=color:#e6db74>\n关键字: </span><span style=color:#e6db74>${</span><span style=color:#a6e22e>paper</span>.<span style=color:#a6e22e>keywords</span>.<span style=color:#a6e22e>join</span>(<span style=color:#e6db74>&#39;, &#39;</span>)<span style=color:#e6db74>}</span><span style=color:#e6db74>`</span>;
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>docs</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> <span style=color:#a6e22e>textSplitter</span>.<span style=color:#a6e22e>createDocuments</span>([<span style=color:#a6e22e>text</span>]);
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e>// 构建图
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>await</span> <span style=color:#a6e22e>kg</span>.<span style=color:#a6e22e>buildFromDocuments</span>(<span style=color:#a6e22e>docs</span>, {
</span></span><span style=display:flex><span>      <span style=color:#a6e22e>graph</span>,
</span></span><span style=display:flex><span>      <span style=color:#a6e22e>mergeEntities</span><span style=color:#f92672>:</span> <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>    });
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>  
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>return</span> <span style=color:#a6e22e>graph</span>;
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// 基于图的检索增强生成
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>async</span> <span style=color:#66d9ef>function</span> <span style=color:#a6e22e>graphBasedAnswering</span>(<span style=color:#a6e22e>graph</span>, <span style=color:#a6e22e>query</span>) {
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>llm</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> <span style=color:#a6e22e>ChatOpenAI</span>({ <span style=color:#a6e22e>model</span><span style=color:#f92672>:</span> <span style=color:#e6db74>&#34;gpt-4&#34;</span> });
</span></span><span style=display:flex><span>  
</span></span><span style=display:flex><span>  <span style=color:#75715e>// 创建图检索器
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>  <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>retriever</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> <span style=color:#a6e22e>GraphRAGRetriever</span>({
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>graph</span>,
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>llm</span>,
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>searchDepth</span><span style=color:#f92672>:</span> <span style=color:#ae81ff>3</span>,  <span style=color:#75715e>// 图搜索深度
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#a6e22e>maxHops</span><span style=color:#f92672>:</span> <span style=color:#ae81ff>2</span>       <span style=color:#75715e>// 最大跳数
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>  });
</span></span><span style=display:flex><span>  
</span></span><span style=display:flex><span>  <span style=color:#75715e>// 创建问答链
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>  <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>chain</span> <span style=color:#f92672>=</span> <span style=color:#a6e22e>RetrievalQAChain</span>.<span style=color:#a6e22e>fromLLM</span>(<span style=color:#a6e22e>llm</span>, <span style=color:#a6e22e>retriever</span>);
</span></span><span style=display:flex><span>  
</span></span><span style=display:flex><span>  <span style=color:#75715e>// 获取答案
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>  <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>response</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> <span style=color:#a6e22e>chain</span>.<span style=color:#a6e22e>invoke</span>({ <span style=color:#a6e22e>query</span> });
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>return</span> <span style=color:#a6e22e>response</span>;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h2 id=总结>总结<a hidden class=anchor aria-hidden=true href=#总结>#</a></h2><p>LangChain Graph为开发者提供了强大的工具集，使从非结构化文本构建知识图谱变得简单而高效。通过结合LLM的语义理解能力与图数据库的结构化表示，它开启了一系列新的应用可能性：</p><ol><li><strong>语义增强的信息检索</strong>：超越简单的关键词匹配</li><li><strong>复杂关系推理</strong>：发现隐藏的知识连接</li><li><strong>上下文感知回答</strong>：基于图结构的精准回答</li><li><strong>知识整合与管理</strong>：连接多源异构数据</li></ol><p>随着LLM技术和图数据库的不断发展，LangChain Graph将在智能知识系统中扮演越来越重要的角色，为构建下一代AI应用提供强大支持。</p><p>无论您是希望增强现有LLM应用的上下文理解能力，还是构建专门的知识管理系统，LangChain Graph都是一个值得深入学习和掌握的强大工具。</p><hr><h2 id=扩展阅读>扩展阅读<a hidden class=anchor aria-hidden=true href=#扩展阅读>#</a></h2><ul><li><a href=https://js.langchain.com/docs/modules/chains/additional/graph_qa>LangChain官方文档：Graphs模块</a></li><li><a href=https://neo4j.com/developer/cypher/langchain-neo4j/>Neo4j与LangChain集成指南</a></li><li><a href=https://github.com/langchain-ai/langchain/blob/master/docs/docs/use_cases/graph/quickstart.ipynb>知识图谱构建最佳实践</a></li><li><a href=https://arxiv.org/abs/2308.06845>图神经网络与LLM结合案例</a></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://realtime-ai.chat/tags/langchain/>LangChain</a></li><li><a href=https://realtime-ai.chat/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/>知识图谱</a></li><li><a href=https://realtime-ai.chat/tags/graph/>Graph</a></li><li><a href=https://realtime-ai.chat/tags/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/>大语言模型</a></li><li><a href=https://realtime-ai.chat/tags/llm/>LLM</a></li></ul><nav class=paginav><a class=prev href=https://realtime-ai.chat/2024/12/28/langchain-%E4%B8%8E-llm-%E7%9A%84%E7%BB%93%E5%90%88%E4%BD%BF%E7%94%A8%E8%AF%A6%E8%A7%A3/><span class=title>« Prev</span><br><span>LangChain 与 LLM 的结合使用详解</span>
</a><a class=next href=https://realtime-ai.chat/2024/12/26/%E5%AE%9E%E6%97%B6agent%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E4%B8%8E%E5%BA%94%E7%94%A8%E5%89%8D%E6%99%AF/><span class=title>Next »</span><br><span>实时Agent系统技术演进与应用前景</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share LangChain Graph 详解：构建智能知识图谱 on x" href="https://x.com/intent/tweet/?text=LangChain%20Graph%20%e8%af%a6%e8%a7%a3%ef%bc%9a%e6%9e%84%e5%bb%ba%e6%99%ba%e8%83%bd%e7%9f%a5%e8%af%86%e5%9b%be%e8%b0%b1&amp;url=https%3a%2f%2frealtime-ai.chat%2f2024%2f12%2f27%2flangchain-graph-%25E8%25AF%25A6%25E8%25A7%25A3%25E6%259E%2584%25E5%25BB%25BA%25E6%2599%25BA%25E8%2583%25BD%25E7%259F%25A5%25E8%25AF%2586%25E5%259B%25BE%25E8%25B0%25B1%2f&amp;hashtags=LangChain%2c%e7%9f%a5%e8%af%86%e5%9b%be%e8%b0%b1%2cGraph%2c%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%2cLLM"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share LangChain Graph 详解：构建智能知识图谱 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2frealtime-ai.chat%2f2024%2f12%2f27%2flangchain-graph-%25E8%25AF%25A6%25E8%25A7%25A3%25E6%259E%2584%25E5%25BB%25BA%25E6%2599%25BA%25E8%2583%25BD%25E7%259F%25A5%25E8%25AF%2586%25E5%259B%25BE%25E8%25B0%25B1%2f&amp;title=LangChain%20Graph%20%e8%af%a6%e8%a7%a3%ef%bc%9a%e6%9e%84%e5%bb%ba%e6%99%ba%e8%83%bd%e7%9f%a5%e8%af%86%e5%9b%be%e8%b0%b1&amp;summary=LangChain%20Graph%20%e8%af%a6%e8%a7%a3%ef%bc%9a%e6%9e%84%e5%bb%ba%e6%99%ba%e8%83%bd%e7%9f%a5%e8%af%86%e5%9b%be%e8%b0%b1&amp;source=https%3a%2f%2frealtime-ai.chat%2f2024%2f12%2f27%2flangchain-graph-%25E8%25AF%25A6%25E8%25A7%25A3%25E6%259E%2584%25E5%25BB%25BA%25E6%2599%25BA%25E8%2583%25BD%25E7%259F%25A5%25E8%25AF%2586%25E5%259B%25BE%25E8%25B0%25B1%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share LangChain Graph 详解：构建智能知识图谱 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2frealtime-ai.chat%2f2024%2f12%2f27%2flangchain-graph-%25E8%25AF%25A6%25E8%25A7%25A3%25E6%259E%2584%25E5%25BB%25BA%25E6%2599%25BA%25E8%2583%25BD%25E7%259F%25A5%25E8%25AF%2586%25E5%259B%25BE%25E8%25B0%25B1%2f&title=LangChain%20Graph%20%e8%af%a6%e8%a7%a3%ef%bc%9a%e6%9e%84%e5%bb%ba%e6%99%ba%e8%83%bd%e7%9f%a5%e8%af%86%e5%9b%be%e8%b0%b1"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share LangChain Graph 详解：构建智能知识图谱 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2frealtime-ai.chat%2f2024%2f12%2f27%2flangchain-graph-%25E8%25AF%25A6%25E8%25A7%25A3%25E6%259E%2584%25E5%25BB%25BA%25E6%2599%25BA%25E8%2583%25BD%25E7%259F%25A5%25E8%25AF%2586%25E5%259B%25BE%25E8%25B0%25B1%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share LangChain Graph 详解：构建智能知识图谱 on whatsapp" href="https://api.whatsapp.com/send?text=LangChain%20Graph%20%e8%af%a6%e8%a7%a3%ef%bc%9a%e6%9e%84%e5%bb%ba%e6%99%ba%e8%83%bd%e7%9f%a5%e8%af%86%e5%9b%be%e8%b0%b1%20-%20https%3a%2f%2frealtime-ai.chat%2f2024%2f12%2f27%2flangchain-graph-%25E8%25AF%25A6%25E8%25A7%25A3%25E6%259E%2584%25E5%25BB%25BA%25E6%2599%25BA%25E8%2583%25BD%25E7%259F%25A5%25E8%25AF%2586%25E5%259B%25BE%25E8%25B0%25B1%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share LangChain Graph 详解：构建智能知识图谱 on telegram" href="https://telegram.me/share/url?text=LangChain%20Graph%20%e8%af%a6%e8%a7%a3%ef%bc%9a%e6%9e%84%e5%bb%ba%e6%99%ba%e8%83%bd%e7%9f%a5%e8%af%86%e5%9b%be%e8%b0%b1&amp;url=https%3a%2f%2frealtime-ai.chat%2f2024%2f12%2f27%2flangchain-graph-%25E8%25AF%25A6%25E8%25A7%25A3%25E6%259E%2584%25E5%25BB%25BA%25E6%2599%25BA%25E8%2583%25BD%25E7%259F%25A5%25E8%25AF%2586%25E5%259B%25BE%25E8%25B0%25B1%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share LangChain Graph 详解：构建智能知识图谱 on ycombinator" href="https://news.ycombinator.com/submitlink?t=LangChain%20Graph%20%e8%af%a6%e8%a7%a3%ef%bc%9a%e6%9e%84%e5%bb%ba%e6%99%ba%e8%83%bd%e7%9f%a5%e8%af%86%e5%9b%be%e8%b0%b1&u=https%3a%2f%2frealtime-ai.chat%2f2024%2f12%2f27%2flangchain-graph-%25E8%25AF%25A6%25E8%25A7%25A3%25E6%259E%2584%25E5%25BB%25BA%25E6%2599%25BA%25E8%2583%25BD%25E7%259F%25A5%25E8%25AF%2586%25E5%259B%25BE%25E8%25B0%25B1%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://realtime-ai.chat/>Chico Gong's Tech Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>